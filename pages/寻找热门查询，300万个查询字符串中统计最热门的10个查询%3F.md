- Why
- What
	- 搜索引擎会通过日志文件把用户每次检索使用的所有检索串都记录下来，每个查询串的长度为1-255字节。假设目前有一千万个记录(这些查询串的重复度比较高，虽然总数是1千万，但如果除去重复后，不超过3百万个。一个查询串的重复度越高，说明查询它的用户越多，也就是越热门)，请你统计最热门的10个查询串，要求使用的内存不能超过1G
- How
	- 分析
		- 由于去重后只有300万的Query，每个Query 255 Bytes，如果全部放入内存，大小为3M*1K/4 = 0.75G，故可以将所有字符串都放在内存进行处理
		- 因此，放弃分而治之/Hash映射的步骤，直接Hash统计，然后排序
		- 针对此类典型的TOP K问题，采取的对策往往是: hashmap + 堆
	- 步骤
		- 先对这批海量数据预处理。具体方法是: 维护一个Key为Query字串，Value为该Query出现次数的HashTable，即hash_map(Query，Value)，每次读取一个Query，如果该字串不在Table中，那么加入该字串，并且将Value值设为1；如果该字串在Table中，那么将该字串的计数加一即可。最终我们在O(N)的时间复杂度内用Hash表完成了统计
		  logseq.order-list-type:: number
		- 堆排序。借助堆这个数据结构，找出Top K，时间复杂度为N‘logK。即借助堆结构，我们可以在log量级的时间内查找和调整/移动。因此，维护一个K(该题目中是10)大小的小根堆，然后遍历300万的Query，分别和根元素进行对比
		  logseq.order-list-type:: number
		- 最终的时间复杂度是: O(N) + N' * O(logK)，(N为1000万，N’为300万）
		  logseq.order-list-type:: number
- How Good
- Refs
- See Also
	- [[Top K问题]]